services:
  # 1. Nginx Reverse Proxy (Entry Point)
  nginx:
    image: nginx:latest
    container_name: prescription_proxy
    ports:
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./config/certs:/etc/nginx/certs:ro
    depends_on:
      - api
    restart: unless-stopped

  # 2. Python API Service
  api:
    build:
      context: ./api
    container_name: prescription_api
    volumes:
      - ./api:/app
      # Persist the vector database
      - vectorstores:/app/vectorstores
      # Mount the policies folder so the script can see them
      - ./Policies:/app/Policies:ro 
    env_file:
      - .env
    environment:
      # Hardcoded to 'ollama' to ensure it matches the service name below
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped

  # 3. Ollama AI Engine (Optimized for RTX 5090)
  ollama:
    image: ollama/ollama
    container_name: ollama_server
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    
    # CRITICAL: Increases shared memory to prevent crashes with large models
    shm_size: 32gb
    
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

# Named volumes for persistence
volumes:
  vectorstores:
  ollama_models: